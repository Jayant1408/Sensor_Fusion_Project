# Project 2.2: Multi-Target Tracking with Extended Kalman Filter

## üéØ Objectives

- ‚úÖ Built an Extended Kalman Filter (EKF) to estimate object states from noisy sensor measurements.
- ‚úÖ Implemented a robust track management system for track initialization, confirmation, and deletion.
- ‚úÖ Solved the data association problem using Single Nearest Neighbor (SNN) with validation gating.
- ‚úÖ Applied sensor fusion by integrating LiDAR and camera-based object detections.
- ‚úÖ Evaluated multi-target tracking (MTT) performance using metrics such as RMSE and BEV visualizations.

---

## üß≠ Introduction

<img src="out/report/2022-11-23-Output-7-Step-4-Multi-Target-Sensor-Fusion-Tracking-Results-Sequence-1-Frames-0-200.gif" width="90%" height="90%" alt="Figure 1. Multi-target tracking results using camera-LiDAR fusion on Sequence 1 (frames 0‚Äì200) from the Waymo Open Dataset.">

In this project, we developed a sensor fusion system capable of tracking multiple vehicles over time. Using real-world data from the [Waymo Open Dataset](https://waymo.com/open), we fused 3D LiDAR detections with camera-based object detections generated in [Project 2.1](https://github.com/jonathanloganmoran/ND0013-Self-Driving-Car-Engineer/tree/main/2-Sensor-Fusion/2-1-3D-Object-Detection-with-LiDAR-Data). These fused observations were processed through a custom-built non-linear [Extended Kalman Filter (EKF)](https://en.wikipedia.org/wiki/Extended_Kalman_filter), paired with a comprehensive track management and data association pipeline. Our system reliably tracked vehicles across suburban scenes under various visibility conditions.

---

## üìÇ File Descriptions

| Filename                        | Description |
|--------------------------------|-------------|
| `setup.py`                     | Installs the project in editable mode and resolves dependencies. |
| `loop_over_dataset.py`         | Main script to load, visualize, and evaluate tracking over range images. |
| `data/filenames.txt`           | List of `.tfrecord` files used for evaluation. |
| `student/filter.py`            | EKF class with nonlinear predict and update logic. |
| `student/trackmanagement.py`   | Manages track lifecycle including initialization and scoring. |
| `student/association.py`       | Associates measurements to tracks using Mahalanobis distance and gating. |
| `misc/measurements.py`         | Defines sensor models, measurement noise, and coordinate transforms. |
| `misc/params.py`               | Contains system configuration and tuning parameters. |

---

## üß† Key Modules Recap

### 1. Extended Kalman Filter (EKF)
We implemented a nonlinear EKF for state estimation, incorporating custom motion and measurement models, Jacobian computation, and process noise modeling.

### 2. Track Management
A full lifecycle system manages track states including tentative confirmation and pruning of inactive or low-score tracks.

### 3. Data Association
Used Mahalanobis distance with validation gating to associate observations to tracks reliably, reducing mismatches and ID switches.

### 4. Camera-LiDAR Sensor Fusion
Fused bounding boxes from camera and LiDAR using projection matrices and non-linear models to improve spatial accuracy, especially under occlusion or partial visibility.

---

## ‚úÖ Results Achieved

- Consistent multi-object tracking with minimal ID switches.
- Low Root Mean Square Error (RMSE) on selected evaluation sequences.
- Improved temporal consistency of object tracks due to fusion and gating logic.

---

## üí° Challenges Faced

The most technically demanding aspect was the implementation of the non-linear camera model and frame transformation logic. Proper tuning of gating thresholds and handling asynchronous sensor updates required extensive experimentation.

---

## üîÑ Benefits of Camera-LiDAR Fusion

- **Theoretical Advantage:** LiDAR provides accurate spatial depth while the camera offers rich semantic context. Fusing them combines precision and classification power.
- **Practical Observation:** Fusion improved robustness in scenarios where LiDAR was sparse (e.g., distant vehicles) or occluded.

---

## ‚ö†Ô∏è Real-World Sensor Fusion Challenges

- Calibration drift between sensors
- Temporal misalignment and delays
- Occlusion and noisy detections
- Sensor degradation over time

These issues were observed during development, particularly timing offsets and false positives in cluttered scenes.

---

## üöÄ Future Work

- Integrate motion models based on object class (e.g., pedestrian vs. vehicle).
- Explore advanced association algorithms like JPDA or MHT.
- Implement temporal filters to reduce noisy updates from camera input.
- Fuse additional modalities such as radar for redundancy and robustness.

---